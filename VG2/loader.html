<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
    <title>Virgo Gabrielle - 2D Shader Glass</title>

    <style>
        @font-face {
            font-family: 'madloud';
            src: url('./madloud.otf') format('opentype');
            font-weight: normal;
            font-style: normal;
            font-display: swap;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html,
        body {
            width: 100%;
            height: 100%;
            background: #000000;
            overflow: hidden;
            touch-action: none;
        }

        #canvas-container {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 1;
        }

        #text-canvas {
            display: none;
        }

        .status-display {
            position: fixed;
            bottom: 30px;
            left: 50%;
            transform: translateX(-50%);
            z-index: 100;
            text-align: center;
            pointer-events: none;
        }

        .loading-text {
            font-size: 12px;
            letter-spacing: 0.4em;
            text-transform: uppercase;
            color: rgba(255, 255, 255, 0.8);
            margin-bottom: 8px;
            animation: pulse 2s infinite;
        }

        .input-indicators {
            display: flex;
            gap: 15px;
            justify-content: center;
        }

        .indicator {
            font-size: 9px;
            letter-spacing: 0.1em;
            text-transform: uppercase;
            color: rgba(255, 255, 255, 0.3);
            display: flex;
            align-items: center;
            opacity: 0.5;
        }

        .indicator.active {
            color: #c9a962;
            opacity: 1;
        }

        .indicator::before {
            content: '';
            width: 4px;
            height: 4px;
            border-radius: 50%;
            background: currentColor;
            margin-right: 6px;
        }

        .tap-prompt {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.7);
            z-index: 200;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            opacity: 1;
            transition: opacity 0.3s ease;
        }

        .tap-prompt.hidden {
            opacity: 0;
            pointer-events: none;
        }

        .tap-prompt-text {
            font-size: 14px;
            letter-spacing: 0.3em;
            text-transform: uppercase;
            color: rgba(255, 255, 255, 0.9);
            margin-bottom: 20px;
        }

        .tap-prompt-icon {
            width: 60px;
            height: 60px;
            border: 2px solid rgba(255, 255, 255, 0.5);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            animation: tapPulse 1.5s infinite;
        }

        .tap-prompt-icon::after {
            content: '';
            width: 20px;
            height: 20px;
            background: rgba(255, 255, 255, 0.8);
            border-radius: 50%;
        }

        @keyframes tapPulse {
            0%, 100% {
                transform: scale(1);
                opacity: 1;
            }
            50% {
                transform: scale(1.1);
                opacity: 0.7;
            }
        }

        @keyframes pulse {
            0%,
            100% {
                opacity: 0.4;
            }

            50% {
                opacity: 1;
            }
        }
    </style>
</head>

<body>
    <div style="font-family: 'madloud'; position: absolute; visibility: hidden;">.</div>
    <div id="canvas-container"></div>
    <canvas id="text-canvas"></canvas>

    <!-- Tap prompt for permissions -->
    <div class="tap-prompt" id="tapPrompt">
        <div class="tap-prompt-text">Tap to enable camera</div>
        <div class="tap-prompt-icon"></div>
    </div>

    <div class="status-display">
        <div class="loading-text" id="mainStatus">LOADING</div>
        <div class="input-indicators">
            <div class="indicator" id="ind-manual">Touch/Mouse</div>
            <div class="indicator" id="ind-sensor">Sensor</div>
        </div>
    </div>

    <!-- Load Three.js first -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>

    <script>
        const CONFIG = {
            imagePath: './new-img.png',
            depthPath: './new-depth.png',

            parallaxStrength: 25,
            inputSensitivity: 10,
            smoothing: 0.25,
            chromaticAberration: 0.015,
            noiseAmount: 0.03,
            zoomLevel: 0.85,

            glass: {
                refraction: 0.05,
                dispersion: 0.018,
                bevelSize: 12.0,
                fresnel: 0.55,
                specular: 0.7,
                specularSize: 44.0,
                brightness: 1.15,
                saturation: 1.15,
                glassParallaxStrength: 0.012,
                gabrielleParallaxBoost: 0.01
            },

            manualInputTimeout: 2000,
        };

        const state = {
            sensor: { x: 0, y: 0, available: false },
            manual: { x: 0, y: 0, lastActivity: 0 },
            viewX: 0, viewY: 0,
            currentInput: 'none',
        };

        let virgoTexture, gabrielleTexture;

        function createSingleTextTexture(text, yPos, fontSize) {
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');

            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;

            ctx.clearRect(0, 0, canvas.width, canvas.height);

            const w = canvas.width;

            ctx.textAlign = 'center';
            ctx.textBaseline = 'middle';
            ctx.fillStyle = '#FFFFFF';

            ctx.font = `${fontSize}px madloud, Arial Black, sans-serif`;
            ctx.fillText(text, w / 2, yPos);

            const tex = new THREE.CanvasTexture(canvas);
            tex.minFilter = THREE.LinearFilter;
            tex.magFilter = THREE.LinearFilter;
            return tex;
        }

        function createTextTextures() {
            return; // ADD THIS LINE TO HIDE TEXT
            const w = window.innerWidth;
            const h = window.innerHeight;
            const commonSize = Math.min(Math.max(60, w * 0.1), 180);

            const gabrielleY = h - 220;
            const virgoY = gabrielleY - (commonSize * 0.85);

            if (virgoTexture) virgoTexture.dispose();
            if (gabrielleTexture) gabrielleTexture.dispose();

            virgoTexture = createSingleTextTexture('virgo', virgoY, commonSize);
            gabrielleTexture = createSingleTextTexture('gabrielle', gabrielleY, commonSize);

            if (virgoMesh) virgoMesh.material.uniforms.uMask.value = virgoTexture;
            if (gabrielleMesh) gabrielleMesh.material.uniforms.uMask.value = gabrielleTexture;
        }

        let scene, camera, renderer;
        let backgroundMesh, virgoMesh, gabrielleMesh;
        let backgroundTexture, depthTexture;
        let bgRenderTarget;
        let time = 0;

        const vertShader = `
            varying vec2 vUv;
            void main() {
                vUv = uv;
                gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
            }
        `;

        const bgFragShader = `
            precision highp float;
            varying vec2 vUv;
            
            uniform sampler2D uImage;
            uniform sampler2D uDepth;
            uniform vec2 uViewOffset;
            uniform float uStrength;
            uniform float uZoom;
            uniform float uCA;
            uniform float uNoise;
            uniform float uTime;
            uniform vec2 uRes;
            uniform vec2 uImgRes;
            
            float hash(vec2 p) {
                return fract(sin(dot(p, vec2(12.9898, 78.233))) * 43758.5453);
            }
            
            void main() {
                float scrAspect = uRes.x / uRes.y;
                float imgAspect = uImgRes.x / uImgRes.y;
                
                vec2 scale = scrAspect > imgAspect 
                    ? vec2(imgAspect / scrAspect, 1.0)
                    : vec2(1.0, scrAspect / imgAspect);
                
                vec2 uv = (vUv - 0.5) / scale + 0.5;
                
                if (uv.x < 0.0 || uv.x > 1.0 || uv.y < 0.0 || uv.y > 1.0) {
                    gl_FragColor = vec4(0.0, 0.0, 0.0, 1.0);
                    return;
                }
                
                uv = uv * uZoom + (1.0 - uZoom) * 0.5;
                
                float depth = texture2D(uDepth, uv).r;
                vec2 off = -uViewOffset * depth * uStrength;
                
                float dist = length(uViewOffset) * 2.0;
                float ca = uCA * (1.0 + dist);
                
                float r = texture2D(uImage, uv + off + uViewOffset * ca * depth).r;
                float g = texture2D(uImage, uv + off).g;
                float b = texture2D(uImage, uv + off - uViewOffset * ca * depth).b;
                
                vec3 col = vec3(r, g, b);
                col += (hash(floor(vUv * uRes * 0.5) + uTime * 0.1) * 2.0 - 1.0) * uNoise;
                
                gl_FragColor = vec4(col, 1.0);
            }
        `;

        const glassFragShader = `
            precision highp float;
            varying vec2 vUv;
            
            uniform sampler2D uBg; 
            uniform sampler2D uMask; 
            uniform vec2 uViewOffset;
            uniform vec2 uRes;
            uniform float uTime;
            uniform float uGlassParallaxStrength;
            uniform float uParallaxBoost;
            
            uniform float uRefraction;
            uniform float uDispersion;
            uniform float uBevelSize;
            uniform float uFresnel;
            uniform float uSpecular;
            uniform float uSpecularSize;
            uniform float uBrightness;
            uniform float uSaturation;
            
            float getMask(vec2 uv) {
                return texture2D(uMask, uv).r;
            }
            
            vec2 getGradient(vec2 uv) {
                vec2 px = vec2(1.0) / uRes;
                float l = getMask(uv - vec2(px.x, 0.0));
                float r = getMask(uv + vec2(px.x, 0.0));
                float d = getMask(uv - vec2(0.0, px.y));
                float u = getMask(uv + vec2(0.0, px.y));
                return vec2(r - l, u - d);
            }
            
            float fresnelSchlick(float cosTheta, float f0) {
                return f0 + (1.0 - f0) * pow(1.0 - cosTheta, 5.0);
            }
            
            vec3 adjustSat(vec3 c, float s) {
                float g = dot(c, vec3(0.299, 0.587, 0.114));
                return mix(vec3(g), c, s);
            }
            
            void main() {
                vec2 glassParallaxOffset = uViewOffset * (uGlassParallaxStrength + uParallaxBoost);

                vec2 maskUv = vUv - glassParallaxOffset;
                float mask = getMask(maskUv);
                
                if (mask < 0.05) {
                    gl_FragColor = vec4(0.0);
                    return;
                }
                
                vec2 px = vec2(1.0) / uRes;
                vec2 gradient = getGradient(maskUv);
                float gradLen = length(gradient);
                
                float dist = 1.0 - mask;
                float bevelFactor = smoothstep(0.0, uBevelSize * px.x, dist);
                
                vec2 gradDir = gradLen > 0.001 ? gradient / gradLen : vec2(0.0);
                
                float angle = (1.0 - bevelFactor) * 1.5708; 
                float nz = cos(angle) * 0.9; 
                float nxy = sin(angle);     
                
                vec3 normal = normalize(vec3(gradDir * nxy, nz));
                
                vec3 viewDir = normalize(vec3(-uViewOffset * 0.5, 1.0));
                vec3 lightDir = normalize(vec3(0.3 - uViewOffset.x * 0.3, 0.5 + uViewOffset.y * 0.3, 1.0));
                
                vec2 refractBase = normal.xy * uRefraction;
                refractBase += uViewOffset * uRefraction * 0.3; 
                
                vec2 refractR = refractBase * (1.0 - uDispersion);
                vec2 refractG = refractBase;
                vec2 refractB = refractBase * (1.0 + uDispersion);
                
                float r = texture2D(uBg, vUv + refractR).r;
                float g = texture2D(uBg, vUv + refractG).g;
                float b = texture2D(uBg, vUv + refractB).b;
                
                vec3 refracted = vec3(r, g, b);
                
                refracted = adjustSat(refracted, uSaturation);
                refracted *= uBrightness;
                
                float NdotV = max(dot(normal, viewDir), 0.0);
                float fresnel = fresnelSchlick(NdotV, 0.04) * uFresnel;
                
                vec3 reflectColor = vec3(1.0, 0.85, 0.0) * 0.5;
                
                vec3 halfVec = normalize(lightDir + viewDir);
                float NdotH = max(dot(normal, halfVec), 0.0);
                float spec = pow(NdotH, uSpecularSize) * uSpecular;
                
                vec3 specColor = vec3(1.0, 0.95, 0.7) * spec;
                
                vec3 color = refracted;
                color = mix(color, reflectColor, fresnel * 0.3);
                color += specColor;
                
                float edgeDarkness = smoothstep(0.0, 0.4, dist) * 0.4;
                color *= 1.0 - edgeDarkness;
                
                float alpha = smoothstep(0.0, 0.15, mask);
                
                gl_FragColor = vec4(color, alpha);
            }
        `;

        async function loadTex(url) {
            return new Promise((res, rej) => {
                new THREE.TextureLoader().load(url, res, undefined, rej);
            });
        }

        async function initThree() {
            const container = document.getElementById('canvas-container');

            scene = new THREE.Scene();
            camera = new THREE.OrthographicCamera(-1, 1, 1, -1, 0.1, 10);
            camera.position.z = 1;

            renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
            container.appendChild(renderer.domElement);

            const dpr = Math.min(window.devicePixelRatio, 2);
            bgRenderTarget = new THREE.WebGLRenderTarget(
                window.innerWidth * dpr,
                window.innerHeight * dpr,
                { minFilter: THREE.LinearFilter, magFilter: THREE.LinearFilter }
            );

            try {
                backgroundTexture = await loadTex(CONFIG.imagePath);
                depthTexture = await loadTex(CONFIG.depthPath);

                createTextTextures();

                const bgMat = new THREE.ShaderMaterial({
                    uniforms: {
                        uImage: { value: backgroundTexture },
                        uDepth: { value: depthTexture },
                        uViewOffset: { value: new THREE.Vector2() },
                        uStrength: { value: CONFIG.parallaxStrength / 1000 },
                        uZoom: { value: CONFIG.zoomLevel },
                        uCA: { value: CONFIG.chromaticAberration },
                        uNoise: { value: CONFIG.noiseAmount },
                        uTime: { value: 0 },
                        uRes: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
                        uImgRes: { value: new THREE.Vector2(backgroundTexture.image.width, backgroundTexture.image.height) }
                    },
                    vertexShader: vertShader,
                    fragmentShader: bgFragShader
                });
                backgroundMesh = new THREE.Mesh(new THREE.PlaneGeometry(2, 2), bgMat);
                scene.add(backgroundMesh);

                const glassUniforms = {
                    uBg: { value: bgRenderTarget.texture },
                    uViewOffset: { value: new THREE.Vector2() },
                    uRes: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
                    uTime: { value: 0 },
                    uGlassParallaxStrength: { value: CONFIG.glass.glassParallaxStrength },

                    uRefraction: { value: CONFIG.glass.refraction },
                    uDispersion: { value: CONFIG.glass.dispersion },
                    uBevelSize: { value: CONFIG.glass.bevelSize },
                    uFresnel: { value: CONFIG.glass.fresnel },
                    uSpecular: { value: CONFIG.glass.specular },
                    uSpecularSize: { value: CONFIG.glass.specularSize },
                    uBrightness: { value: CONFIG.glass.brightness },
                    uSaturation: { value: CONFIG.glass.saturation },
                };

                const virgoMat = new THREE.ShaderMaterial({
                    uniforms: {
                        ...glassUniforms,
                        uMask: { value: virgoTexture },
                        uParallaxBoost: { value: 0.0 }
                    },
                    vertexShader: vertShader,
                    fragmentShader: glassFragShader,
                    transparent: true
                });
                virgoMesh = new THREE.Mesh(new THREE.PlaneGeometry(2, 2), virgoMat);
                virgoMesh.renderOrder = 1;
                scene.add(virgoMesh);

                const gabrielleMat = new THREE.ShaderMaterial({
                    uniforms: {
                        ...glassUniforms,
                        uMask: { value: gabrielleTexture },
                        uParallaxBoost: { value: CONFIG.glass.gabrielleParallaxBoost }
                    },
                    vertexShader: vertShader,
                    fragmentShader: glassFragShader,
                    transparent: true
                });
                gabrielleMesh = new THREE.Mesh(new THREE.PlaneGeometry(2, 2), gabrielleMat);
                gabrielleMesh.renderOrder = 2;
                scene.add(gabrielleMesh);

                document.getElementById('mainStatus').textContent = 'READY';

            } catch (e) {
                console.error('Init failed:', e);
                document.getElementById('mainStatus').textContent = 'ERROR (Check Console)';
            }

            window.addEventListener('resize', onResize);
        }

        function onResize() {
            const w = window.innerWidth, h = window.innerHeight;
            const dpr = Math.min(window.devicePixelRatio, 2);

            renderer.setSize(w, h);
            bgRenderTarget.setSize(w * dpr, h * dpr);

            if (backgroundMesh) backgroundMesh.material.uniforms.uRes.value.set(w, h);
            if (virgoMesh) virgoMesh.material.uniforms.uRes.value.set(w, h);
            if (gabrielleMesh) gabrielleMesh.material.uniforms.uRes.value.set(w, h);

            createTextTextures();
        }

        function render() {
            time += 0.016;

            if (backgroundMesh) {
                backgroundMesh.material.uniforms.uViewOffset.value.set(state.viewX, state.viewY);
                backgroundMesh.material.uniforms.uTime.value = time;
            }

            if (virgoMesh) virgoMesh.visible = false;
            if (gabrielleMesh) gabrielleMesh.visible = false;

            renderer.setRenderTarget(bgRenderTarget);
            renderer.render(scene, camera);

            if (virgoMesh) virgoMesh.visible = true;
            if (gabrielleMesh) gabrielleMesh.visible = true;

            renderer.setRenderTarget(null);

            if (virgoMesh) {
                virgoMesh.material.uniforms.uViewOffset.value.set(state.viewX, state.viewY);
                virgoMesh.material.uniforms.uTime.value = time;
            }
            if (gabrielleMesh) {
                gabrielleMesh.material.uniforms.uViewOffset.value.set(state.viewX, state.viewY);
                gabrielleMesh.material.uniforms.uTime.value = time;
            }

            renderer.render(scene, camera);
        }

        // --- INPUT LOGIC ---
        function initInput() {
            document.addEventListener('mousemove', e => {
                state.manual.lastActivity = Date.now();
                state.manual.x = (e.clientX / window.innerWidth - 0.5) * 3;
                state.manual.y = -(e.clientY / window.innerHeight - 0.5) * 3;
            });

            let lx = 0, ly = 0, ox = 0, oy = 0;

            document.addEventListener('touchstart', e => {
                state.manual.lastActivity = Date.now();
                lx = e.touches[0].clientX;
                ly = e.touches[0].clientY;
            }, { passive: true });

            document.addEventListener('touchmove', e => {
                state.manual.lastActivity = Date.now();
                ox = Math.max(-1.5, Math.min(1.5, ox + (e.touches[0].clientX - lx) / window.innerWidth * 5));
                oy = Math.max(-1.5, Math.min(1.5, oy - (e.touches[0].clientY - ly) / window.innerHeight * 5));
                state.manual.x = ox;
                state.manual.y = oy;
                lx = e.touches[0].clientX;
                ly = e.touches[0].clientY;
            }, { passive: true });
        }

        // Check if we're on mobile
        function isMobileDevice() {
            return /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent) 
                || ('ontouchstart' in window && window.innerWidth < 1024);
        }

        // Check if on secure context (HTTPS or localhost)
        function isSecureContext() {
            return window.isSecureContext || location.protocol === 'https:' || location.hostname === 'localhost';
        }

        // Show/hide tap prompt
        function showTapPrompt() {
            const prompt = document.getElementById('tapPrompt');
            if (prompt) prompt.classList.remove('hidden');
        }

        function hideTapPrompt() {
            const prompt = document.getElementById('tapPrompt');
            if (prompt) prompt.classList.add('hidden');
        }

        // Initialize face tracking with parallax-effect library
        async function initFaceTracking() {
            console.log('Starting face tracking init...');
            document.getElementById('mainStatus').textContent = 'REQUESTING CAMERA';
            
            // First, manually request camera permission
            // This ensures the browser shows the permission prompt
            try {
                console.log('Requesting camera permission...');
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                console.log('Camera permission granted!');
                
                // Stop the stream - the parallax library will request its own
                stream.getTracks().forEach(track => track.stop());
                
            } catch (e) {
                console.error('Camera permission denied or error:', e.name, e.message);
                document.getElementById('mainStatus').textContent = 'CAMERA DENIED';
                return; // Don't bother loading the library
            }
            
            // Now load the parallax library
            document.getElementById('mainStatus').textContent = 'LOADING LIBRARY';
            console.log('Loading parallax library...');
            
            const script = document.createElement('script');
            script.src = 'https://cdn.jsdelivr.net/npm/parallax-effect/dist/parallax-effect.min.js';
            script.onload = () => {
                console.log('Parallax library loaded, Parallax object:', typeof Parallax);
                
                if (typeof Parallax !== 'undefined') {
                    document.getElementById('mainStatus').textContent = 'INIT FACE TRACKING';
                    console.log('Calling Parallax.init()...');
                    
                    Parallax.init(v => {
                        state.sensor.x = v.x * CONFIG.inputSensitivity;
                        state.sensor.y = -v.y * CONFIG.inputSensitivity;
                        state.sensor.available = true;
                    }, { smoothEye: 0.8, smoothDist: 0.2, threshold: 0.5 })
                        .then(() => {
                            console.log('Face tracking ready!');
                            document.getElementById('mainStatus').textContent = 'READY';
                        })
                        .catch(e => {
                            console.error('Face tracking failed:', e);
                            console.error('Error name:', e.name);
                            console.error('Error message:', e.message);
                            document.getElementById('mainStatus').textContent = 'ERROR: ' + (e.message || 'TRACKING FAILED');
                        });
                } else {
                    console.error('Parallax object not found after script load');
                    document.getElementById('mainStatus').textContent = 'ERROR: LIB NOT FOUND';
                }
            };
            script.onerror = (e) => {
                console.error('Parallax library failed to load:', e);
                document.getElementById('mainStatus').textContent = 'ERROR: LIB FAILED';
            };
            document.body.appendChild(script);
        }

        // Setup based on device type
        function setupSensors() {
            const prompt = document.getElementById('tapPrompt');
            
            if (isMobileDevice() && isSecureContext()) {
                // MOBILE + HTTPS: Show tap prompt, then init face tracking
                // Camera requires user gesture on mobile
                showTapPrompt();
                
                const handleTap = (e) => {
                    e.preventDefault();
                    prompt.removeEventListener('click', handleTap);
                    prompt.removeEventListener('touchend', handleTap);
                    hideTapPrompt();
                    
                    // Init face tracking after user gesture
                    initFaceTracking();
                };

                prompt.addEventListener('click', handleTap);
                prompt.addEventListener('touchend', handleTap);
            } else if (!isMobileDevice()) {
                // DESKTOP: Init face tracking directly (browser will prompt for camera)
                hideTapPrompt();
                initFaceTracking();
            } else {
                // MOBILE + HTTP: Can't use camera, just hide prompt
                hideTapPrompt();
                console.log('Camera not available (requires HTTPS)');
                document.getElementById('mainStatus').textContent = 'READY (NO CAMERA)';
            }
        }

        async function init() {
            console.log('Starting...');
            console.log('Mobile:', isMobileDevice(), 'Secure:', isSecureContext());
            
            // Ensure container exists
            const container = document.getElementById('canvas-container');
            if (!container) {
                console.error('Container not found, retrying...');
                setTimeout(init, 50);
                return;
            }
            
            // Wait for font to be ready
            await document.fonts.ready;
            
            // Init Three.js scene
            await initThree();
            
            // Start render loop immediately - mouse/touch works right away
            initInput();
            
            function loop() {
                const manual = Date.now() - state.manual.lastActivity < CONFIG.manualInputTimeout;

                let tx = 0, ty = 0;
                if (manual) {
                    tx = state.manual.x;
                    ty = state.manual.y;
                    state.currentInput = 'manual';
                } else if (state.sensor.available) {
                    tx = state.sensor.x;
                    ty = state.sensor.y;
                    state.currentInput = 'sensor';
                } else {
                    state.currentInput = 'none';
                }

                state.viewX += (tx - state.viewX) * CONFIG.smoothing;
                state.viewY += (ty - state.viewY) * CONFIG.smoothing;

                document.getElementById('ind-manual').classList.toggle('active', state.currentInput === 'manual');
                document.getElementById('ind-sensor').classList.toggle('active', state.currentInput === 'sensor');

                render();
                requestAnimationFrame(loop);
            }

            loop();
            
            // Setup sensors after a brief delay to let the page render
            setTimeout(setupSensors, 100);
        }

        // Start when ready
        if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', init);
        } else {
            init();
        }
    </script>
</body>

</html>
