<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <title>lysets.slør</title>
  <style>
    body, html {
      margin: 0;
      padding: 0;
      overflow: hidden;
      background-color: #000;
      font-family: Arial, sans-serif;
    }
    canvas {
      width: 100vw;
      height: 100vh;
      display: block;
    }
    #motionBtn {
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      padding: 20px 40px;
      font-size: 18px;
      background: rgba(255, 255, 255, 0.1);
      color: white;
      border: 2px solid rgba(255, 255, 255, 0.3);
      border-radius: 30px;
      cursor: pointer;
      z-index: 100;
      backdrop-filter: blur(10px);
      transition: all 0.3s ease;
    }
    #motionBtn:hover {
      background: rgba(255, 255, 255, 0.2);
      border-color: rgba(255, 255, 255, 0.5);
    }
    #orientationInfo {
      position: fixed;
      top: 10px;
      left: 10px;
      color: white;
      font-size: 12px;
      opacity: 0.5;
      z-index: 100;
      display: none;
    }
  </style>
</head>
<body>
  <canvas id="shaderCanvas"></canvas>
  <button id="motionBtn">Enable Motion Control</button>
  <div id="orientationInfo">
    <div>Alpha: <span id="alpha">0</span>°</div>
    <div>Beta: <span id="beta">0</span>°</div>
    <div>Gamma: <span id="gamma">0</span>°</div>
  </div>
  
  <script>
    class OrganicFluidTransition {
      constructor() {
        this.canvas = document.getElementById('shaderCanvas');
        this.gl = this.canvas.getContext('webgl2');
        if (!this.gl) {
          alert('Your browser does not support WebGL2');
          return;
        }
  
        // Determine device type (mobile or desktop)
        this.isMobile = ('ontouchstart' in window) || (navigator.maxTouchPoints > 0);
        
        // Build image paths dynamically based on device type (images 2.JPG to 33.JPG)
        const folder = this.isMobile ? './img/mobile/' : './img/desktop/';
        this.imagePaths = [];
        for (let i = 2; i <= 33; i++) {
          this.imagePaths.push(folder + i + '.JPG');
        }
        // Randomize the order of image paths.
        this.shuffleArray(this.imagePaths);
        
        // Transition multiplier for motion control
        this.transitionMultiplier = 1.0;
        
        // Motion control variables
        this.useMotionControl = false;
        this.orientation = { alpha: 0, beta: 0, gamma: 0 };
        this.baseOrientation = null;
        this.smoothedOrientation = { alpha: 0, beta: 0, gamma: 0 };
        this.previousAlpha = 0;
        this.lastImageIndex = 0;
        
        // Mouse/touch positions (fallback and desktop)
        this.mouseX = 0;
        this.mouseY = 0;
        this.smoothedMouseX = 0;
        this.lastMouseX = 0;
        this.lastMouseY = 0;
        this.lastInteractionTime = performance.now() / 1000;
        this.moveThreshold = 0.1;
  
        // Fractal time is driven by movement
        this.fractalTime = 0;
        this.lastFrameTime = performance.now() / 1000;
  
        // Vertex shader: simple pass-through that forwards UV coordinates.
        this.vertexShaderSource = `#version 300 es
          in vec4 a_position;
          in vec2 a_texCoord;
          out vec2 v_texCoord;
          void main() {
            gl_Position = a_position;
            v_texCoord = a_texCoord;
          }
        `;
  
        this.fragmentShaderSource = `#version 300 es
          precision highp float;
          #define PI 3.14159265359
  
          // Uniforms
          uniform sampler2D u_image0;
          uniform sampler2D u_image1;
          uniform sampler2D u_dispVideo;
          uniform vec2 u_resolution;
          uniform float u_time;
          uniform float u_fractalIntensity;
          uniform float u_dispAmount;
          uniform float u_dispScale;
          uniform float u_transition;
          uniform float u_imageCount;
  
          in vec2 v_texCoord;
          out vec4 outColor;
  
          vec4 baseTransition() {
            float transitionVal = u_transition * u_imageCount;
            float blendFactor = fract(transitionVal);
            
            vec2 timeOffset = vec2(0.015 * sin(u_time * 0.25), 0.015 * cos(u_time * 0.25));
            vec2 dispCoord = v_texCoord * u_dispScale + timeOffset;
            vec2 videoDisp = texture(u_dispVideo, dispCoord).rg;
            float watermarkMask = 1.0;
            if (dispCoord.x > 0.7 && dispCoord.y < 0.3) {
              float xFade = smoothstep(0.7, 0.9, dispCoord.x);
              float yFade = smoothstep(0.3, 0.1, dispCoord.y);
              watermarkMask = 1.0 - (xFade * yFade);
              videoDisp = mix(videoDisp, vec2(0.5, 0.5), 1.0 - watermarkMask);
            }
            float dynamicDisp = u_dispAmount * (1.0 + 0.4 * sin(u_time * 0.15));
            vec2 displacement = (videoDisp - 0.5) * dynamicDisp * 1.5 * watermarkMask;
  
            vec2 displacedUV0 = clamp(v_texCoord + displacement * (1.0 - blendFactor), 0.0, 1.0);
            vec2 displacedUV1 = clamp(v_texCoord - displacement * blendFactor, 0.0, 1.0);
  
            vec4 color0 = texture(u_image0, displacedUV0);
            vec4 color1 = texture(u_image1, displacedUV1);
            return mix(color0, color1, blendFactor);
          }
  
          vec4 clearTransition() {
            float transitionVal = u_transition * u_imageCount;
            float blendFactor = fract(transitionVal);
            return mix(texture(u_image0, v_texCoord), texture(u_image1, v_texCoord), blendFactor);
          }
  
          vec3 hsv(float h, float s, float v) {
            vec3 k = vec3(1.0, 2.0/3.0, 1.0/3.0);
            vec3 p = abs(fract(vec3(h) + k) * 6.0 - 3.0);
            return v * mix(vec3(1.0), clamp(p - 1.0, 0.0, 1.0), s);
          }
  
          vec3 formula(in vec2 _p, in vec2 c) {
            vec2 p = _p;
            const float n = 2.0;
            const int iters = 12;
            float timeVal = u_time * 0.1;
            vec3 col = vec3(0.0);
            float t = 1.0;
            float dpp = dot(p, p);
            float lp = sqrt(dpp);
            float r = smoothstep(0.0, 0.2, lp);
            for (int i = 0; i < iters; i++) {
              p = abs(mod(p/dpp + c, n) - n/2.0);
              dpp = dot(p, p);
              lp = sqrt(dpp);
              t *= smoothstep(0.0, 0.01, abs(n/2.0 - p.x)*lp)
                 * smoothstep(0.0, 0.01, abs(n/2.0 - p.y)*lp)
                 * smoothstep(0.0, 0.01, abs(p.x)*2.0)
                 * smoothstep(0.0, 0.01, abs(p.y)*2.0);
              r *= smoothstep(0.0, 0.2, lp);
              col += hsv(1.0 - max(p.x, p.y) + t*2.0 + timeVal, 2.0 - lp + t, r);
            }
            return (-cos(col / 4.0)*0.5 + 0.5) * t;
          }
  
          vec3 newShaderEffect(vec2 fragCoord) {
            vec2 p = -1.0 + 2.0 * fragCoord / u_resolution;
            p.x *= u_resolution.x / u_resolution.y;
            p *= 2.0;
            const vec2 e = vec2(0.06545465634, -0.05346356485);
            vec2 c = u_time * e;
            vec3 col = vec3(0.0);
            const float blursamples = 4.0;
            float sbs = sqrt(blursamples);
            float mbluramount = 1.0 / u_resolution.x / length(e) / blursamples * 2.0;
            float aabluramount = 1.0 / u_resolution.x / sbs * 4.0;
            for (float b = 0.0; b < blursamples; b++) {
              col += formula(
                p + vec2(mod(b, sbs)*aabluramount, floor(b/sbs)*aabluramount),
                c + e * mbluramount * b
              );
            }
            col /= blursamples;
            return col;
          }
  
          vec3 colorDodgeBlend(vec3 base, vec3 blend) {
            return clamp(base / (1.0 - blend + 0.001), 0.0, 1.0);
          }
  
          void main() {
            float transitionVal = u_transition * u_imageCount;
            float blendFactor = fract(transitionVal);
  
            vec4 clearColor = clearTransition();
            vec4 distortedColor = baseTransition();
  
            float clearPulse = 1.0 - abs(blendFactor - 0.5) * 4.0;
            clearPulse = clamp(clearPulse, 0.0, 1.0);
  
            vec4 finalBase = mix(distortedColor, clearColor, clearPulse);
  
            vec3 fractalEffect = newShaderEffect(gl_FragCoord.xy) * u_fractalIntensity * (1.0 - clearPulse);
  
            vec3 finalColor = colorDodgeBlend(finalBase.rgb, fractalEffect);
            outColor = vec4(finalColor, 1.0);
          }
        `;
  
        this.program = this.createShaderProgram();
        this.setupBuffers();
        this.loadTextures();
        this.loadDispTexture();
        this.setupEventListeners();
        this.render();
      }
  
      shuffleArray(array) {
        for (let i = array.length - 1; i > 0; i--) {
          const j = Math.floor(Math.random() * (i + 1));
          [array[i], array[j]] = [array[j], array[i]];
        }
      }
  
      createShaderProgram() {
        const gl = this.gl;
        const vertexShader = gl.createShader(gl.VERTEX_SHADER);
        gl.shaderSource(vertexShader, this.vertexShaderSource);
        gl.compileShader(vertexShader);
        if (!gl.getShaderParameter(vertexShader, gl.COMPILE_STATUS)) {
          console.error('Vertex shader error:', gl.getShaderInfoLog(vertexShader));
        }
        const fragmentShader = gl.createShader(gl.FRAGMENT_SHADER);
        gl.shaderSource(fragmentShader, this.fragmentShaderSource);
        gl.compileShader(fragmentShader);
        if (!gl.getShaderParameter(fragmentShader, gl.COMPILE_STATUS)) {
          console.error('Fragment shader error:', gl.getShaderInfoLog(fragmentShader));
        }
        const program = gl.createProgram();
        gl.attachShader(program, vertexShader);
        gl.attachShader(program, fragmentShader);
        gl.linkProgram(program);
        if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
          console.error('Program linking error:', gl.getProgramInfoLog(program));
        }
        return program;
      }
  
      setupBuffers() {
        const gl = this.gl;
        const positionBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
        const positions = [
          -1.0, -1.0,
           1.0, -1.0,
          -1.0,  1.0,
          -1.0,  1.0,
           1.0, -1.0,
           1.0,  1.0
        ];
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(positions), gl.STATIC_DRAW);
  
        const texCoordBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, texCoordBuffer);
        const texCoords = [
          0.0, 0.0,
          1.0, 0.0,
          0.0, 1.0,
          0.0, 1.0,
          1.0, 0.0,
          1.0, 1.0
        ];
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(texCoords), gl.STATIC_DRAW);
  
        gl.useProgram(this.program);
        const posLoc = gl.getAttribLocation(this.program, 'a_position');
        const texLoc = gl.getAttribLocation(this.program, 'a_texCoord');
        gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
        gl.enableVertexAttribArray(posLoc);
        gl.vertexAttribPointer(posLoc, 2, gl.FLOAT, false, 0, 0);
        gl.bindBuffer(gl.ARRAY_BUFFER, texCoordBuffer);
        gl.enableVertexAttribArray(texLoc);
        gl.vertexAttribPointer(texLoc, 2, gl.FLOAT, false, 0, 0);
      }
  
      loadTextures() {
        const gl = this.gl;
        this.textures = [];
        this.images = [];
        this.imagePaths.forEach(path => {
          const img = new Image();
          img.src = path;
          this.images.push(img);
        });
        Promise.all(this.images.map(img => new Promise(resolve => {
          if (img.complete) resolve();
          else img.onload = resolve;
        }))).then(() => {
          this.images.forEach(image => {
            const texture = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, texture);
            gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image);
            this.textures.push(texture);
          });
          this.resizeCanvas();
        }).catch(err => console.error('Error loading base images:', err));
      }
  
      loadDispTexture() {
        const gl = this.gl;
        this.dispVideoTexture = gl.createTexture();
        gl.bindTexture(gl.TEXTURE_2D, this.dispVideoTexture);
        gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, 480, 270, 0, gl.RGBA, gl.UNSIGNED_BYTE, null);
      }
  
      updateVideoTexture() {
        if (!this.video) {
          this.video = document.createElement('video');
          const videoPath = this.isMobile ? "./dispvid4mobile.mp4" : "./dispvid4.mp4";
          this.video.src = videoPath;
          this.video.loop = true;
          this.video.muted = true;
          this.video.playsInline = true;
          
          // Add error handling
          this.video.onerror = (e) => {
            console.error(`Failed to load video: ${videoPath}`, e);
            console.log('Video error details:', this.video.error);
            // Create a fallback texture if video fails
            this.createFallbackDisplacementTexture();
          };
          
          this.video.onloadeddata = () => {
            console.log(`Video loaded successfully: ${videoPath}`);
          };
        }
        if (!this.video.paused && this.video.readyState >= this.video.HAVE_CURRENT_DATA) {
          const gl = this.gl;
          gl.bindTexture(gl.TEXTURE_2D, this.dispVideoTexture);
          gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
          gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, this.video);
        }
      }
      
      createFallbackDisplacementTexture() {
        const gl = this.gl;
        // Create a procedural noise texture as fallback
        const size = 256;
        const data = new Uint8Array(size * size * 4);
        
        for (let i = 0; i < size * size * 4; i += 4) {
          // Create some noise pattern
          const noise = Math.random();
          const value = Math.floor(128 + noise * 127);
          data[i] = value;     // R
          data[i + 1] = value; // G
          data[i + 2] = value; // B
          data[i + 3] = 255;   // A
        }
        
        gl.bindTexture(gl.TEXTURE_2D, this.dispVideoTexture);
        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, size, size, 0, gl.RGBA, gl.UNSIGNED_BYTE, data);
        console.log('Using fallback displacement texture');
      }
  
      handleOrientation(event) {
        if (!this.useMotionControl) return;
        
        // Store previous alpha for haptic feedback
        this.previousAlpha = this.orientation.alpha || 0;
        
        this.orientation.alpha = event.alpha || 0;
        this.orientation.beta = event.beta || 0;
        this.orientation.gamma = event.gamma || 0;
        
        // Set base orientation on first reading
        if (!this.baseOrientation) {
          this.baseOrientation = {
            alpha: this.orientation.alpha,
            beta: this.orientation.beta,
            gamma: this.orientation.gamma
          };
        }
        
        // Update debug info if visible
        if (document.getElementById('orientationInfo').style.display === 'block') {
          document.getElementById('alpha').textContent = Math.round(this.orientation.alpha);
          document.getElementById('beta').textContent = Math.round(this.orientation.beta);
          document.getElementById('gamma').textContent = Math.round(this.orientation.gamma);
        }
        
        this.lastInteractionTime = performance.now() / 1000;
      }
  
      setupEventListeners() {
        // Desktop mouse movement
        window.addEventListener('mousemove', e => {
          if (!this.useMotionControl) {
            this.mouseX = e.clientX;
            this.mouseY = e.clientY;
            this.lastInteractionTime = performance.now() / 1000;
          }
        });
        
        // Touch events for mobile fallback
        window.addEventListener('touchmove', e => {
          if (!this.useMotionControl && e.touches.length > 0) {
            this.mouseX = e.touches[0].clientX;
            this.mouseY = e.touches[0].clientY;
            this.lastInteractionTime = performance.now() / 1000;
          }
        });
        
        // Device orientation events
        window.addEventListener('deviceorientation', e => this.handleOrientation(e));
        
        // Motion control button
        const motionBtn = document.getElementById('motionBtn');
        motionBtn.addEventListener('click', async () => {
          if (this.isMobile && typeof DeviceOrientationEvent !== 'undefined') {
            // Check if we need to request permission (iOS 13+)
            if (typeof DeviceOrientationEvent.requestPermission === 'function') {
              try {
                const permission = await DeviceOrientationEvent.requestPermission();
                if (permission === 'granted') {
                  this.useMotionControl = true;
                  motionBtn.style.display = 'none';
                  // Show a brief haptic pulse to confirm activation
                  if ('vibrate' in navigator) {
                    navigator.vibrate([50, 30, 50]); // Pattern: vibrate-pause-vibrate
                  }
                  // Uncomment next line to show debug info
                  // document.getElementById('orientationInfo').style.display = 'block';
                } else {
                  alert('Motion permission denied. You can still use touch controls.');
                }
              } catch (error) {
                console.error('Error requesting device orientation permission:', error);
                alert('Unable to access motion sensors. You can still use touch controls.');
              }
            } else {
              // Non-iOS or older iOS
              this.useMotionControl = true;
              motionBtn.style.display = 'none';
              // Show a brief haptic pulse to confirm activation
              if ('vibrate' in navigator) {
                navigator.vibrate([50, 30, 50]); // Pattern: vibrate-pause-vibrate
              }
              // Uncomment next line to show debug info
              // document.getElementById('orientationInfo').style.display = 'block';
            }
          } else {
            // Hide button on desktop
            motionBtn.style.display = 'none';
          }
        });
        
        // Auto-hide motion button on desktop
        if (!this.isMobile) {
          motionBtn.style.display = 'none';
        }
        
        window.addEventListener('resize', () => {
          this.resizeCanvas();
        });
      }
  
      resizeCanvas() {
        this.canvas.width = window.innerWidth;
        this.canvas.height = window.innerHeight;
        this.gl.viewport(0, 0, this.canvas.width, this.canvas.height);
      }
  
      render() {
        const gl = this.gl;
        const now = performance.now() / 1000;
        const deltaTime = now - this.lastFrameTime;
        this.lastFrameTime = now;
  
        let targetX = this.mouseX;
        let movementSpeed = 0;
  
        if (this.useMotionControl && this.baseOrientation) {
          // Calculate relative orientation
          let relativeAlpha = this.orientation.alpha - this.baseOrientation.alpha;
          let relativeBeta = this.orientation.beta - this.baseOrientation.beta;
          let relativeGamma = this.orientation.gamma - this.baseOrientation.gamma;
          
          // Normalize alpha to 0-360 range for full rotation
          if (relativeAlpha < 0) relativeAlpha += 360;
          if (relativeAlpha > 360) relativeAlpha -= 360;
          
          // Use alpha (compass heading) for full 360° navigation
          targetX = (relativeAlpha / 360) * this.canvas.width;
          
          // Calculate movement speed from orientation change
          const orientationDelta = Math.abs(this.orientation.alpha - this.smoothedOrientation.alpha) +
                                  Math.abs(this.orientation.beta - this.smoothedOrientation.beta) * 0.3 +
                                  Math.abs(this.orientation.gamma - this.smoothedOrientation.gamma) * 0.3;
          movementSpeed = orientationDelta * 0.5;
          
          // Smooth orientation values
          this.smoothedOrientation.alpha = this.smoothedOrientation.alpha * 0.9 + this.orientation.alpha * 0.1;
          this.smoothedOrientation.beta = this.smoothedOrientation.beta * 0.9 + this.orientation.beta * 0.1;
          this.smoothedOrientation.gamma = this.smoothedOrientation.gamma * 0.9 + this.orientation.gamma * 0.1;
        } else {
          // Calculate movement speed from mouse/touch
          const dx = this.mouseX - this.lastMouseX;
          const dy = this.mouseY - this.lastMouseY;
          movementSpeed = Math.sqrt(dx * dx + dy * dy);
        }
  
        // Update smoothed position
        this.smoothedMouseX = this.smoothedMouseX * 0.95 + targetX * 0.05;
  
        // Play or pause video based on recent interaction
        const timeSinceMove = now - this.lastInteractionTime;
        if (timeSinceMove < this.moveThreshold || (this.useMotionControl && movementSpeed > 0.1)) {
          if (this.video && this.video.paused && this.video.error === null) {
            this.video.play().catch(err => {
              // Silently handle play errors since we have fallback
              console.log("Video play attempted but failed:", err.message);
            });
          }
        } else {
          if (this.video && !this.video.paused) {
            this.video.pause();
          }
        }
  
        // Update fractal time based on movement
        const speedFactor = 0.015;
        this.fractalTime += movementSpeed * speedFactor;
        
        this.lastMouseX = this.mouseX;
        this.lastMouseY = this.mouseY;
  
        this.updateVideoTexture();
        gl.clearColor(0, 0, 0, 1);
        gl.clear(gl.COLOR_BUFFER_BIT);
  
        if (!this.textures || this.textures.length < 2) {
          requestAnimationFrame(() => this.render());
          return;
        }
  
        gl.useProgram(this.program);
  
        const resLoc = gl.getUniformLocation(this.program, 'u_resolution');
        const timeLoc = gl.getUniformLocation(this.program, 'u_time');
        const fractalIntensityLoc = gl.getUniformLocation(this.program, 'u_fractalIntensity');
        const dispAmountLoc = gl.getUniformLocation(this.program, 'u_dispAmount');
        const dispScaleLoc = gl.getUniformLocation(this.program, 'u_dispScale');
        const transitionLoc = gl.getUniformLocation(this.program, 'u_transition');
        const imageCountLoc = gl.getUniformLocation(this.program, 'u_imageCount');
        
        gl.uniform2f(resLoc, this.canvas.width, this.canvas.height);
        gl.uniform1f(timeLoc, this.fractalTime);
        gl.uniform1f(fractalIntensityLoc, 0.5);
        gl.uniform1f(dispAmountLoc, 0.05);
        gl.uniform1f(dispScaleLoc, 1.0);
        
        const t = (this.smoothedMouseX / this.canvas.width) * this.transitionMultiplier;
        gl.uniform1f(transitionLoc, t);
        gl.uniform1f(imageCountLoc, this.imagePaths.length);
  
        const transitionVal = t * this.imagePaths.length;
        const baseIndex = Math.floor(transitionVal) % this.imagePaths.length;
        const nextIndex = (baseIndex + 1) % this.imagePaths.length;
        
        // Haptic feedback when crossing image boundaries
        if (this.useMotionControl && 'vibrate' in navigator) {
          const currentImageIndex = Math.floor(transitionVal);
          if (currentImageIndex !== this.lastImageIndex && this.lastImageIndex !== undefined) {
            // Short haptic pulse when transitioning to a new image
            navigator.vibrate(20);
          }
          this.lastImageIndex = currentImageIndex;
        }
  
        const img0Loc = gl.getUniformLocation(this.program, 'u_image0');
        const img1Loc = gl.getUniformLocation(this.program, 'u_image1');
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, this.textures[baseIndex]);
        gl.uniform1i(img0Loc, 0);
        gl.activeTexture(gl.TEXTURE1);
        gl.bindTexture(gl.TEXTURE_2D, this.textures[nextIndex]);
        gl.uniform1i(img1Loc, 1);
  
        const dispVideoLoc = gl.getUniformLocation(this.program, 'u_dispVideo');
        gl.activeTexture(gl.TEXTURE2);
        gl.bindTexture(gl.TEXTURE_2D, this.dispVideoTexture);
        gl.uniform1i(dispVideoLoc, 2);
  
        gl.drawArrays(gl.TRIANGLES, 0, 6);
        requestAnimationFrame(() => this.render());
      }
    }
  
    window.addEventListener('load', () => {
      new OrganicFluidTransition();
    });
  </script>
</body>
</html>
