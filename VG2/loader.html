<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
    <title>Virgo Gabrielle - Loader</title>
    
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }

        html, body {
            width: 100%;
            height: 100%;
            background: #000000;
            overflow: hidden;
            touch-action: none; /* Prevents unwanted scrolling/zooming */
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            display: flex;
            justify-content: center;
            align-items: flex-start;
        }

        /* Image canvas - Middle Layer (The main 3D-effect image) */
        #depthCanvas {
            position: absolute;
            top: 0;
            left: 50%;
            transform: translateX(-50%);
            
            /* Crucial Responsive Constraints for Mobile Visibility */
            max-width: 100vw;
            max-height: 100vh;
            width: auto;
            height: auto;
            object-fit: contain; /* Ensures image fits within bounds */
            
            z-index: 1; 
            pointer-events: none; 
        }

        /* Prism shader - Top Layer (The glowing overlay effect) */
        #prismCanvas {
            position: fixed;
            top: 0; left: 0;
            width: 100%; height: 100%;
            z-index: 2;
            pointer-events: none;
            mix-blend-mode: lighten;
            opacity: 0.6;
        }

        /* Loading / Status Indicator */
        .status-display {
            position: fixed;
            bottom: 30px;
            left: 50%;
            transform: translateX(-50%);
            z-index: 100;
            text-align: center;
            width: 100%;
            pointer-events: none;
        }

        .loading-text {
            font-size: 12px;
            letter-spacing: 0.4em;
            text-transform: uppercase;
            color: rgba(255, 255, 255, 0.8);
            margin-bottom: 8px;
            animation: pulse 2s infinite;
        }

        .input-indicators {
            display: flex;
            gap: 15px;
            justify-content: center;
        }

        .indicator {
            font-size: 9px;
            letter-spacing: 0.1em;
            text-transform: uppercase;
            color: rgba(255, 255, 255, 0.3);
            display: flex;
            align-items: center;
            transition: color 0.3s, opacity 0.3s;
            opacity: 0.5;
        }

        .indicator.active {
            color: #c9a962;
            opacity: 1;
        }

        .indicator::before {
            content: '';
            width: 4px;
            height: 4px;
            border-radius: 50%;
            background: currentColor;
            margin-right: 6px;
        }

        @keyframes pulse {
            0%, 100% { opacity: 0.4; }
            50% { opacity: 1; }
        }
    </style>
</head>
<body>
    <canvas id="depthCanvas"></canvas>
    <canvas id="prismCanvas"></canvas>
    
    <div class="status-display">
        <div class="loading-text" id="mainStatus">LOADING</div>
        <div class="input-indicators">
            <div class="indicator" id="ind-manual">Touch/Mouse</div>
            <div class="indicator" id="ind-sensor">Sensor</div>
        </div>
    </div>

    <!-- Face tracking library -->
    <script src="https://cdn.jsdelivr.net/npm/parallax-effect/dist/parallax-effect.min.js"></script>

    <script>
        // ============================================================
        // CONFIGURATION
        // ============================================================
        const CONFIG = {
            imagePath: '/loader-img.png',
            depthPath: '/loader-depth.png',
            
            // TWEAKED SETTINGS
            parallaxStrength: 8,         // Reduced to be very subtle
            inputSensitivity: 7.0,       // Increased for high responsiveness
            smoothing: 0.1,              // Slightly smoother movement
            
            // Visual Effects (from index-gemini1-1.html)
            chromaticAberration: 0.007,  // Subtle channel splitting
            noiseAmount: 0.03,           // Light static noise
            
            // Border Fix (UV Zoom)
            zoomLevel: 0.92,             // 8% Zoom in to hide edges during parallax
        };

        // ============================================================
        // GLOBAL STATE
        // ============================================================
        const state = {
            sensor: { x: 0, y: 0, active: false },
            manual: { x: 0, y: 0, active: false },
            viewX: 0, // Smoothed X input for rendering
            viewY: 0, // Smoothed Y input for rendering
            targetX: 0, // Combined target X
            targetY: 0, // Combined target Y
        };

        // ============================================================
        // VERTEX SHADER (Standard)
        // ============================================================
        const vertexShader = `
            attribute vec2 a_position;
            attribute vec2 a_texCoord;
            varying vec2 v_texCoord;
            void main() {
                gl_Position = vec4(a_position, 0.0, 1.0);
                v_texCoord = a_texCoord;
            }
        `;

        // ============================================================
        // DEPTH PARALLAX SHADER (With Zoom, CA, and Noise)
        // ============================================================
        const depthParallaxShader = `
            precision highp float;
            varying vec2 v_texCoord;
            
            uniform sampler2D u_image;
            uniform sampler2D u_depth;
            uniform vec2 u_viewOffset;
            uniform float u_strength;
            uniform float u_zoom;
            uniform float u_ca;          // Chromatic Aberration strength
            uniform float u_noise;       // Noise strength
            uniform float u_time;
            uniform vec2 u_resolution;
            
            // Simple hash function for pseudo-random noise
            float hash(vec2 p) {
                return fract(sin(dot(p, vec2(12.9898, 78.233))) * 43758.5453);
            }
            
            vec4 sampleDisplaced(vec2 uv, vec2 offset) {
                // Get depth value (0.0 to 1.0)
                float depth = texture2D(u_depth, uv).r;
                
                // Calculate base offset
                vec2 baseOffset = -u_viewOffset * depth * u_strength;
                
                // --- Chromatic Aberration ---
                // Sample different channels with slight offsets based on depth and view
                vec2 offsetR = baseOffset + u_viewOffset * u_ca * depth;
                vec2 offsetB = baseOffset - u_viewOffset * u_ca * depth;

                float r = texture2D(u_image, uv + offsetR).r;
                float g = texture2D(u_image, uv + baseOffset).g;
                float b = texture2D(u_image, uv + offsetB).b;

                vec4 color = vec4(r, g, b, 1.0);

                // Check edges and fade alpha if pulled outside the zoomed bounds
                if (uv.x + offsetR.x < 0.0 || uv.x + offsetR.x > 1.0 || 
                    uv.y + offsetR.y < 0.0 || uv.y + offsetR.y > 1.0 ||
                    uv.x + offsetB.x < 0.0 || uv.x + offsetB.x > 1.0 || 
                    uv.y + offsetB.y < 0.0 || uv.y + offsetB.y > 1.0) {
                    color.a = 0.0;
                }

                return color;
            }

            void main() {
                // 1. Apply Zoom (Crop into the image)
                // This creates the "safety buffer" of pixels
                float margin = (1.0 - u_zoom) * 0.5;
                vec2 uv = v_texCoord * u_zoom + margin;
                
                vec4 finalColor = sampleDisplaced(uv, u_viewOffset);
                
                // 2. --- Noise Effect ---
                // Add pseudo-random noise based on screen coordinate and time
                float noise = hash(floor(v_texCoord * u_resolution * 0.5) + u_time * 0.1) * 2.0 - 1.0;
                
                // Apply noise evenly to RGB channels
                finalColor.rgb += noise * u_noise * finalColor.a;

                gl_FragColor = finalColor;
            }
        `;

        // ============================================================
        // PRISM SHADER (Unchanged from previous iteration)
        // ============================================================
        const prismBufferShader = `
            precision highp float;
            varying vec2 v_texCoord;
            uniform float u_time;
            uniform vec2 u_resolution;
            uniform vec2 u_mouse;
            uniform sampler2D u_buffer;

            #define R u_resolution

            vec2 tile(vec2 v) {
                return ((fract(v) * 2.0 - 1.0) * sign(fract(0.5 * v) * 2.0 - 1.0)) * 0.5 + 0.5;
            }

            vec4 A(vec2 U) {
                return texture2D(u_buffer, tile(U / R));
            }

            void main() {
                vec2 U = v_texCoord * R;
                vec2 e = u_mouse;
                vec4 Q = vec4(120.0) * exp(-2e2 * length(U - e) / R.y);
                
                e = (0.5 + 0.35 * vec2(sin(0.15 * u_time), cos(0.1 * u_time))) * R;
                Q += vec4(12.0 + 8.0 * sin(u_time * 0.3), 10.0 - 8.0 * sin(u_time * 0.3), -8.0 * sin(0.2 * u_time), 10.0) 
                     * exp(-10e1 * length(U - e) / R.y);
                
                float a = 0.02 * u_time;
                float c = cos(a), s = sin(a);
                mat2 m = mat2(c, -s, s, c);
                
                vec3 o = vec3(U - 0.5 * R, 0.0);
                o.xy *= m;
                
                a = 0.08 * sin(0.08 * u_time);
                c = cos(a); s = sin(a);
                m = mat2(c, -s, s, c);
                o.yz *= m;
                
                for (float i = -15.0; i < 15.0; i++) {
                    vec2 u = (1.2 + 0.2 * sin(0.15 * u_time)) * -o.xy + 0.5 * R + 0.004 * R.y * i;
                    Q += 0.1 * A(u) * exp(-1.2 * abs(2.0 - 0.2 * i - vec4(1.0, 2.0, 3.0, 4.0)));
                }
                gl_FragColor = Q;
            }
        `;

        const prismImageShader = `
            precision highp float;
            varying vec2 v_texCoord;
            uniform vec2 u_resolution;
            uniform sampler2D u_buffer;
            #define R u_resolution
            void main() {
                vec2 U = v_texCoord * R;
                vec4 a = texture2D(u_buffer, U / R);
                vec4 Q = vec4(0.0);
                Q += a.x * exp(-abs(0.5 - vec4(1.0, 2.0, 3.0, 4.0)));
                Q += a.y * exp(-abs(1.5 - vec4(1.0, 2.0, 3.0, 4.0)));
                Q += a.z * exp(-abs(2.5 - vec4(1.0, 2.0, 3.0, 4.0)));
                Q += a.w * exp(-abs(3.5 - vec4(1.0, 2.0, 3.0, 4.0)));
                gl_FragColor = Q;
            }
        `;

        // ============================================================
        // UTILS
        // ============================================================
        function createShader(gl, type, source) {
            const shader = gl.createShader(type);
            gl.shaderSource(shader, source);
            gl.compileShader(shader);
            if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                 console.error('Shader compilation error:', gl.getShaderInfoLog(shader));
                 return null;
            }
            return shader;
        }

        function createProgram(gl, vsSource, fsSource) {
            const program = gl.createProgram();
            const vs = createShader(gl, gl.VERTEX_SHADER, vsSource);
            const fs = createShader(gl, gl.FRAGMENT_SHADER, fsSource);
            if (!vs || !fs) return null;
            
            gl.attachShader(program, vs);
            gl.attachShader(program, fs);
            gl.linkProgram(program);
            if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
                console.error('Program linking error:', gl.getProgramInfoLog(program));
                return null;
            }
            return program;
        }

        function loadImage(src) {
            return new Promise((resolve, reject) => {
                const img = new Image();
                img.crossOrigin = "anonymous"; 
                img.onload = () => resolve(img);
                img.onerror = () => reject(new Error(`Failed to load ${src}`));
                img.src = src;
            });
        }

        // ============================================================
        // DEPTH RENDERER
        // ============================================================
        class DepthParallaxRenderer {
            constructor(canvas) {
                this.canvas = canvas;
                // Attempt to get context, handle potential mobile issues (too large canvas, etc.)
                this.gl = canvas.getContext('webgl', { 
                    antialias: true, 
                    alpha: true,
                    premultipliedAlpha: false 
                });
                this.ready = false;
            }
            
            async init(imageSrc, depthSrc) {
                const gl = this.gl;
                if (!gl) {
                    console.error("WebGL context not available. Mobile issue?");
                    return;
                }
                
                try {
                    const [image, depth] = await Promise.all([
                        loadImage(imageSrc),
                        loadImage(depthSrc)
                    ]);
                    
                    // Set internal resolution to match image. CSS handles scaling.
                    this.canvas.width = image.naturalWidth;
                    this.canvas.height = image.naturalHeight;
                    
                    gl.viewport(0, 0, this.canvas.width, this.canvas.height);
                    
                    this.program = createProgram(gl, vertexShader, depthParallaxShader);
                    if (!this.program) throw new Error("Shader program failed to initialize.");
                    
                    const positions = new Float32Array([-1, -1, 1, -1, -1, 1, 1, 1]);
                    const texCoords = new Float32Array([0, 1, 1, 1, 0, 0, 1, 0]);
                    
                    const posBuffer = gl.createBuffer();
                    gl.bindBuffer(gl.ARRAY_BUFFER, posBuffer);
                    gl.bufferData(gl.ARRAY_BUFFER, positions, gl.STATIC_DRAW);
                    
                    const texBuffer = gl.createBuffer();
                    gl.bindBuffer(gl.ARRAY_BUFFER, texBuffer);
                    gl.bufferData(gl.ARRAY_BUFFER, texCoords, gl.STATIC_DRAW);
                    
                    this.imageTexture = this.createTexture(image);
                    this.depthTexture = this.createTexture(depth);
                    
                    gl.useProgram(this.program);
                    this.uniforms = {
                        image: gl.getUniformLocation(this.program, 'u_image'),
                        depth: gl.getUniformLocation(this.program, 'u_depth'),
                        viewOffset: gl.getUniformLocation(this.program, 'u_viewOffset'),
                        strength: gl.getUniformLocation(this.program, 'u_strength'),
                        zoom: gl.getUniformLocation(this.program, 'u_zoom'),
                        ca: gl.getUniformLocation(this.program, 'u_ca'),        // CA uniform
                        noise: gl.getUniformLocation(this.program, 'u_noise'),  // Noise uniform
                        time: gl.getUniformLocation(this.program, 'u_time'),    // Time uniform
                        resolution: gl.getUniformLocation(this.program, 'u_resolution'), // Resolution uniform
                        posLoc: gl.getAttribLocation(this.program, 'a_position'),
                        texLoc: gl.getAttribLocation(this.program, 'a_texCoord')
                    };

                    gl.bindBuffer(gl.ARRAY_BUFFER, posBuffer);
                    gl.enableVertexAttribArray(this.uniforms.posLoc);
                    gl.vertexAttribPointer(this.uniforms.posLoc, 2, gl.FLOAT, false, 0, 0);
                    
                    gl.bindBuffer(gl.ARRAY_BUFFER, texBuffer);
                    gl.enableVertexAttribArray(this.uniforms.texLoc);
                    gl.vertexAttribPointer(this.uniforms.texLoc, 2, gl.FLOAT, false, 0, 0);
                    
                    this.startTime = Date.now();
                    this.ready = true;
                    document.getElementById('mainStatus').innerText = 'READY'; // Final ready state
                } catch(e) {
                    console.error("Depth init failed", e);
                    document.getElementById('mainStatus').innerText = 'ERROR';
                }
            }
            
            createTexture(image) {
                const gl = this.gl;
                const texture = gl.createTexture();
                gl.bindTexture(gl.TEXTURE_2D, texture);
                gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
                gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
                gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
                gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
                gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image);
                return texture;
            }
            
            render() {
                if (!this.ready) return;
                const gl = this.gl;
                const time = (Date.now() - this.startTime) / 1000;
                
                gl.clearColor(0, 0, 0, 0);
                gl.clear(gl.COLOR_BUFFER_BIT);
                gl.useProgram(this.program);
                
                gl.activeTexture(gl.TEXTURE0);
                gl.bindTexture(gl.TEXTURE_2D, this.imageTexture);
                gl.uniform1i(this.uniforms.image, 0);
                
                gl.activeTexture(gl.TEXTURE1);
                gl.bindTexture(gl.TEXTURE_2D, this.depthTexture);
                gl.uniform1i(this.uniforms.depth, 1);
                
                // Calculate strength as UV units
                const uvStrength = CONFIG.parallaxStrength / this.canvas.width;
                
                // Pass uniforms
                gl.uniform2f(this.uniforms.viewOffset, state.viewX, state.viewY);
                gl.uniform1f(this.uniforms.strength, uvStrength);
                gl.uniform1f(this.uniforms.zoom, CONFIG.zoomLevel);
                gl.uniform1f(this.uniforms.ca, CONFIG.chromaticAberration);
                gl.uniform1f(this.uniforms.noise, CONFIG.noiseAmount);
                gl.uniform1f(this.uniforms.time, time);
                gl.uniform2f(this.uniforms.resolution, this.canvas.width, this.canvas.height);
                
                gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
            }
        }

        // ============================================================
        // PRISM RENDERER (Unchanged)
        // ============================================================
        class PrismRenderer {
            constructor(canvas) {
                this.canvas = canvas;
                this.gl = canvas.getContext('webgl', { antialias: false, alpha: true });
                this.startTime = Date.now();
                this.fbos = [];
                this.currentBuffer = 0;
                this.ready = false;
            }
            
            init() {
                const gl = this.gl;
                if (!gl) return;
                this.resize();
                
                this.bufferProgram = createProgram(gl, vertexShader, prismBufferShader);
                this.imageProgram = createProgram(gl, vertexShader, prismImageShader);
                if (!this.bufferProgram || !this.imageProgram) {
                     this.ready = false;
                     return;
                }
                
                this.createGeometry();
                this.setupUniforms();
                this.createFramebuffers();
                
                window.addEventListener('resize', () => {
                    this.resize();
                    this.createFramebuffers();
                });
                
                this.ready = true;
            }
            
            resize() {
                // Limit DPR on mobile to prevent crashes from excessive resolution
                const dpr = Math.min(window.devicePixelRatio, 1.5); 
                this.canvas.width = window.innerWidth * dpr;
                this.canvas.height = window.innerHeight * dpr;
                this.canvas.style.width = window.innerWidth + 'px';
                this.canvas.style.height = window.innerHeight + 'px';
                this.gl.viewport(0, 0, this.canvas.width, this.canvas.height);
            }
            
            createGeometry() {
                const gl = this.gl;
                const positions = new Float32Array([-1, -1, 1, -1, -1, 1, 1, 1]);
                const texCoords = new Float32Array([0, 1, 1, 1, 0, 0, 1, 0]);
                
                this.posBuffer = gl.createBuffer();
                gl.bindBuffer(gl.ARRAY_BUFFER, this.posBuffer);
                gl.bufferData(gl.ARRAY_BUFFER, positions, gl.STATIC_DRAW);
                
                this.texBuffer = gl.createBuffer();
                gl.bindBuffer(gl.ARRAY_BUFFER, this.texBuffer);
                gl.bufferData(gl.ARRAY_BUFFER, texCoords, gl.STATIC_DRAW);
            }
            
            setupUniforms() {
                const gl = this.gl;
                this.bufferUniforms = {
                    time: gl.getUniformLocation(this.bufferProgram, 'u_time'),
                    resolution: gl.getUniformLocation(this.bufferProgram, 'u_resolution'),
                    mouse: gl.getUniformLocation(this.bufferProgram, 'u_mouse'),
                    buffer: gl.getUniformLocation(this.bufferProgram, 'u_buffer'),
                };
                this.imageUniforms = {
                    resolution: gl.getUniformLocation(this.imageProgram, 'u_resolution'),
                    buffer: gl.getUniformLocation(this.imageProgram, 'u_buffer'),
                };
            }
            
            createFramebuffers() {
                const gl = this.gl;
                // Clean up existing buffers
                this.fbos.forEach(fbo => {
                    if (fbo.texture) gl.deleteTexture(fbo.texture);
                    if (fbo.framebuffer) gl.deleteFramebuffer(fbo.framebuffer);
                });
                this.fbos = [];
                
                for (let i = 0; i < 2; i++) {
                    const texture = gl.createTexture();
                    gl.bindTexture(gl.TEXTURE_2D, texture);
                    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, this.canvas.width, this.canvas.height, 0, gl.RGBA, gl.UNSIGNED_BYTE, null);
                    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
                    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
                    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
                    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
                    
                    const framebuffer = gl.createFramebuffer();
                    gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);
                    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);
                    
                    this.fbos.push({ texture, framebuffer });
                }
                gl.bindFramebuffer(gl.FRAMEBUFFER, null);
            }
            
            setupAttributes(program) {
                const gl = this.gl;
                gl.bindBuffer(gl.ARRAY_BUFFER, this.posBuffer);
                const posLoc = gl.getAttribLocation(program, 'a_position');
                gl.enableVertexAttribArray(posLoc);
                gl.vertexAttribPointer(posLoc, 2, gl.FLOAT, false, 0, 0);
                gl.bindBuffer(gl.ARRAY_BUFFER, this.texBuffer);
                const texLoc = gl.getAttribLocation(program, 'a_texCoord');
                gl.enableVertexAttribArray(texLoc);
                gl.vertexAttribPointer(texLoc, 2, gl.FLOAT, false, 0, 0);
            }
            
            render() {
                if (!this.ready) return;
                const gl = this.gl;
                const time = (Date.now() - this.startTime) / 1000;
                
                // Map viewX (-1 to 1) to screen space for prism/mouse uniform
                const mouseX = (state.viewX * 0.5 + 0.5) * this.canvas.width;
                const mouseY = (-state.viewY * 0.5 + 0.5) * this.canvas.height;
                
                const readBuffer = this.fbos[this.currentBuffer];
                const writeBuffer = this.fbos[1 - this.currentBuffer];
                
                // 1. Render to buffer (ping-pong)
                gl.bindFramebuffer(gl.FRAMEBUFFER, writeBuffer.framebuffer);
                gl.viewport(0, 0, this.canvas.width, this.canvas.height);
                gl.useProgram(this.bufferProgram);
                this.setupAttributes(this.bufferProgram);
                
                gl.uniform1f(this.bufferUniforms.time, time);
                gl.uniform2f(this.bufferUniforms.resolution, this.canvas.width, this.canvas.height);
                gl.uniform2f(this.bufferUniforms.mouse, mouseX, mouseY);
                
                gl.activeTexture(gl.TEXTURE0);
                gl.bindTexture(gl.TEXTURE_2D, readBuffer.texture);
                gl.uniform1i(this.bufferUniforms.buffer, 0);
                
                gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
                
                this.currentBuffer = 1 - this.currentBuffer; // Flip buffer
                
                // 2. Render to screen
                gl.bindFramebuffer(gl.FRAMEBUFFER, null);
                gl.viewport(0, 0, this.canvas.width, this.canvas.height);
                gl.useProgram(this.imageProgram);
                this.setupAttributes(this.imageProgram);
                gl.uniform2f(this.imageUniforms.resolution, this.canvas.width, this.canvas.height);
                gl.activeTexture(gl.TEXTURE0);
                gl.bindTexture(gl.TEXTURE_2D, writeBuffer.texture);
                gl.uniform1i(this.imageUniforms.buffer, 0);
                gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
            }
        }

        // ============================================================
        // INPUT HANDLERS
        // ============================================================
        
        function initFaceTracking() {
            if (typeof Parallax === 'undefined') return Promise.reject('Parallax library not loaded');
            
            return Parallax.init(view => {
                // Apply Sensitivity 
                state.sensor.x = view.x * CONFIG.inputSensitivity;
                state.sensor.y = -view.y * CONFIG.inputSensitivity;
                
                if (!state.sensor.active) {
                    state.sensor.active = true;
                    document.getElementById('ind-sensor').classList.add('active');
                    if (state.manual.active) { 
                        document.getElementById('ind-manual').classList.remove('active'); 
                        state.manual.active = false;
                    }
                }
            }, {
                smoothEye: 0.8,
                smoothDist: 0.2,
                threshold: 0.5 
            });
        }
        
        function initGyroscope() {
            return new Promise((resolve, reject) => {
                if (!window.DeviceOrientationEvent) {
                    reject('No gyroscope');
                    return;
                }
                
                const handler = (e) => {
                    if (e.gamma === null) return;
                    
                    // Gyro sensitivity 
                    // e.gamma is rotation around Z-axis (left/right tilt)
                    // e.beta is rotation around X-axis (front/back tilt) - standard resting position is ~45 for mobile
                    state.sensor.x = Math.max(-2, Math.min(2, (e.gamma / 30) * CONFIG.inputSensitivity));
                    state.sensor.y = Math.max(-2, Math.min(2, ((e.beta - 45) / 30) * CONFIG.inputSensitivity));
                    
                    if (!state.sensor.active) {
                        state.sensor.active = true;
                        document.getElementById('ind-sensor').classList.add('active');
                        if (state.manual.active) { 
                            document.getElementById('ind-manual').classList.remove('active'); 
                            state.manual.active = false;
                        }
                    }
                };
                
                // iOS 13+ permission request
                if (typeof DeviceOrientationEvent.requestPermission === 'function') {
                    DeviceOrientationEvent.requestPermission()
                        .then(response => {
                            if (response === 'granted') {
                                window.addEventListener('deviceorientation', handler);
                                resolve();
                            } else {
                                reject('Permission denied');
                            }
                        }).catch(reject);
                } else {
                    window.addEventListener('deviceorientation', handler);
                    resolve();
                }
            });
        }
        
        function initManualInput() {
            let offsetX = 0, offsetY = 0;
            const sensitivity = 5.0; // Touch drag sensitivity multiplier
            
            function activateManual() {
                if (!state.manual.active) {
                    state.manual.active = true;
                    document.getElementById('ind-manual').classList.add('active');
                    if (state.sensor.active) { 
                        document.getElementById('ind-sensor').classList.remove('active'); 
                        state.sensor.active = false;
                    }
                }
            }

            // Mouse Input
            document.addEventListener('mousemove', (e) => {
                activateManual();
                // Map mouse position to -1.5 to 1.5 range
                state.manual.x = (e.clientX / window.innerWidth - 0.5) * 3;
                state.manual.y = -(e.clientY / window.innerHeight - 0.5) * 3;
            });

            // Touch Input
            let lastX = 0, lastY = 0;
            document.addEventListener('touchstart', (e) => {
                activateManual();
                const touch = e.touches[0];
                lastX = touch.clientX;
                lastY = touch.clientY;
            }, { passive: true });
            
            document.addEventListener('touchmove', (e) => {
                const touch = e.touches[0];
                const dx = ((touch.clientX - lastX) / window.innerWidth) * sensitivity; 
                const dy = ((touch.clientY - lastY) / window.innerHeight) * sensitivity;
                
                // Accumulate offsets and clamp to prevent excessive drift
                offsetX = Math.max(-1.5, Math.min(1.5, offsetX + dx));
                offsetY = Math.max(-1.5, Math.min(1.5, offsetY - dy)); // Invert Y for touch drag
                
                state.manual.x = offsetX;
                state.manual.y = offsetY;
                
                lastX = touch.clientX;
                lastY = touch.clientY;
            }, { passive: true });
        }


        // ============================================================
        // MAIN
        // ============================================================
        let depthRenderer, prismRenderer;
        
        async function init() {
            depthRenderer = new DepthParallaxRenderer(document.getElementById('depthCanvas'));
            prismRenderer = new PrismRenderer(document.getElementById('prismCanvas'));
            
            try {
                await depthRenderer.init(CONFIG.imagePath, CONFIG.depthPath);
                prismRenderer.init();
            } catch (e) {
                console.error('Failed to initialize renderers:', e);
            }
            
            function render() {
                // Combine and clamp inputs (Sensor takes priority if active, but manual can still influence)
                let targetX = 0, targetY = 0;
                
                if (state.sensor.active) {
                    targetX = state.sensor.x;
                    targetY = state.sensor.y;
                } else if (state.manual.active) {
                    targetX = state.manual.x;
                    targetY = state.manual.y;
                }
                
                state.targetX = targetX;
                state.targetY = targetY;

                // Smooth movement
                state.viewX += (state.targetX - state.viewX) * CONFIG.smoothing;
                state.viewY += (state.targetY - state.viewY) * CONFIG.smoothing;
                
                depthRenderer.render();
                prismRenderer.render();
                
                requestAnimationFrame(render);
            }
            render();
            
            // Init Inputs: Manual input is always available. Sensor takes control if successful.
            initManualInput();
            
            // Try Face/Gyro Tracking (Sensor)
            initFaceTracking().catch(() => {
                if ('ontouchstart' in window) initGyroscope().catch(() => {});
            });

        }
        
        window.addEventListener('DOMContentLoaded', init);
    </script>
</body>
</html>
