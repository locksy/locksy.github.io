<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Mixed Up Mapping (Radius + Angle)</title>
  <style>
    body, html {
      margin: 0;
      padding: 0;
      overflow: hidden;
      background-color: #000;
      font-family: Arial, sans-serif;
    }
    canvas {
      width: 100vw;
      height: 100vh;
      display: block;
    }
    /* Button overlay for requesting motion permission on mobile */
    #motionBtn {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      padding: 1em 2em;
      font-size: 1.2em;
      background-color: rgba(0,0,0,0.8);
      color: #fff;
      border: 2px solid #fff;
      border-radius: 5px;
      z-index: 1000;
      cursor: pointer;
      display: none;
    }
  </style>
</head>
<body>
  <canvas id="shaderCanvas"></canvas>
  <button id="motionBtn">Click for Device Motion</button>
  
  <script>
    class OrganicFluidTransition {
      constructor() {
        this.canvas = document.getElementById('shaderCanvas');
        this.gl = this.canvas.getContext('webgl2');
        if (!this.gl) {
          alert('Your browser does not support WebGL2');
          return;
        }

        // For mobile device orientation handling.
        this.isMobile = (window.DeviceOrientationEvent !== undefined);

        // Base images â€“ ensure these 7 images are in the same folder.
        this.imagePaths = ['1.JPG','2.JPG','3.JPG','4.JPG','5.JPG','6.JPG','7.JPG'];

        // Create the video element for displacement.
        this.video = document.createElement('video');
        this.video.src = "dispvid4.mp4";
        this.video.loop = true;
        this.video.muted = true;
        this.video.playsInline = true;
        // We'll do threshold-based play/pause.

        // Mouse & velocity-based fractal time
        this.mouseX = 0;
        this.mouseY = 0;
        this.lastMouseX = 0;
        this.lastMouseY = 0;

        // For deciding when to play/pause the displacement video
        this.lastMouseMoveTime = 0;
        this.moveThreshold = 0.5; // seconds

        // Our fractal's "time" is advanced by mouse velocity
        this.fractalTime = 0;
        // Keep track of the previous frame time
        this.lastFrameTime = performance.now() / 1000;

        // We'll store the current "transition progress" for blending images,
        // though in this new approach we derive it from angle.
        this.currentTransition = 0.0;

        this.vertexShaderSource = `#version 300 es
          in vec4 a_position;
          in vec2 a_texCoord;
          out vec2 v_texCoord;
          void main() {
            gl_Position = a_position;
            v_texCoord = a_texCoord;
          }
        `;

        this.fragmentShaderSource = `#version 300 es
          precision highp float;
          
          #define PI 3.141592

          // Uniforms
          uniform sampler2D u_image0;
          uniform sampler2D u_image1;
          uniform sampler2D u_dispVideo;
          uniform vec2 u_resolution;
          uniform float u_time;  // fractalTime
          
          // u_transitionProgress - how far we are between two images
          uniform float u_transitionProgress;
          
          // For the fractal
          uniform float u_fractalIntensity;
          
          // For displacement
          uniform float u_dispAmount;
          uniform float u_dispScale;
          
          // We'll also pass a "blendMode" to choose colorDodge/lighten/difference,
          // but that can also come from some function of angle or radius if you prefer
          uniform float u_blendMode;

          in vec2 v_texCoord;
          out vec4 outColor;

          ///////////////////////////
          // Base Transition Effect//
          ///////////////////////////
          vec4 baseTransition() {
            // Simple use: offset the displacement sampling with some function of time
            vec2 timeOffset = vec2(0.015 * sin(u_time * 0.25), 0.015 * cos(u_time * 0.25));
            vec2 dispCoord = v_texCoord * u_dispScale + timeOffset;
            
            // Sample displacement video texture
            vec2 videoDisp = texture(u_dispVideo, dispCoord).rg;
            
            // Example watermark mask
            float watermarkMask = 1.0;
            if (dispCoord.x > 0.7 && dispCoord.y < 0.3) {
              float xFade = smoothstep(0.7, 0.9, dispCoord.x);
              float yFade = smoothstep(0.3, 0.1, dispCoord.y);
              watermarkMask = 1.0 - (xFade * yFade);
              videoDisp = mix(videoDisp, vec2(0.5, 0.5), 1.0 - watermarkMask);
            }
            
            float dynamicDisp = u_dispAmount * (1.0 + 0.4 * sin(u_time * 0.15));
            vec2 displacement = (videoDisp - 0.5) * dynamicDisp * 1.5 * watermarkMask;
            
            float smoothFade = smoothstep(0.0, 1.0, u_transitionProgress);
            
            // Displace image0 in one direction
            vec2 displacedUV0 = clamp(v_texCoord + displacement * (1.0 - smoothFade), 0.0, 1.0);
            // Displace image1 in the opposite direction
            vec2 displacedUV1 = clamp(v_texCoord - displacement * smoothFade, 0.0, 1.0);
            
            vec4 color0 = texture(u_image0, displacedUV0);
            vec4 color1 = texture(u_image1, displacedUV1);
            return mix(color0, color1, smoothFade);
          }
          
          /////////////////////////////////////
          // Fractal Iridescent Shader Effect//
          /////////////////////////////////////
          vec3 hsv(float h, float s, float v) {
            vec3 k = vec3(1.0, 2.0/3.0, 1.0/3.0);
            vec3 p = abs(fract(vec3(h) + k) * 6.0 - 3.0);
            return v * mix(vec3(1.0), clamp(p - 1.0, 0.0, 1.0), s);
          }
          
          vec3 formula(in vec2 p, in vec2 c) {
            const float n = 2.0;
            const int iters = 12;
            float timeVal = u_time * 0.1;
            vec3 col = vec3(0.0);
            float t = 1.0;
            float dpp = dot(p, p);
            float lp = sqrt(dpp);
            float r = smoothstep(0.0, 0.2, lp);
            
            for (int i = 0; i < iters; i++) {
              p = abs(mod(p/dpp + c, n) - n/2.0);
              dpp = dot(p, p);
              lp = sqrt(dpp);
              t *= smoothstep(0.0, 0.01, abs(n/2.0 - p.x) * lp)
                 * smoothstep(0.0, 0.01, abs(n/2.0 - p.y) * lp)
                 * smoothstep(0.0, 0.01, abs(p.x) * 2.0)
                 * smoothstep(0.0, 0.01, abs(p.y) * 2.0);
              r *= smoothstep(0.0, 0.2, lp);
              col += hsv(1.0 - max(p.x, p.y) + t * 2.0 + timeVal, 2.0 - lp + t, r);
            }
            return (-cos(col / 4.0) * 0.5 + 0.5) * t;
          }
          
          vec3 newShaderEffect(vec2 fragCoord) {
            vec2 p = -1.0 + 2.0 * fragCoord / u_resolution;
            p.x *= u_resolution.x / u_resolution.y;
            p *= 2.0;
            const vec2 e = vec2(0.06545465634, -0.05346356485);
            vec2 c = u_time * e;  
            vec3 col = vec3(0.0);
            const float blursamples = 4.0;
            float sbs = sqrt(blursamples);
            float mbluramount = 1.0 / u_resolution.x / length(e) / blursamples * 2.0;
            float aabluramount = 1.0 / u_resolution.x / sbs * 4.0;
            for (float b = 0.0; b < blursamples; b++) {
              col += formula(
                p + vec2(mod(b, sbs) * aabluramount, floor(b / sbs) * aabluramount),
                c + e * mbluramount * b
              );
            }
            col /= blursamples;
            return col;
          }
          
          //////////////////////////////
          // Blend Mode Functions     //
          //////////////////////////////
          vec3 colorDodgeBlend(vec3 base, vec3 blend) {
            return clamp(base / (1.0 - blend + 0.001), 0.0, 1.0);
          }
          
          vec3 lightenBlend(vec3 base, vec3 blend) {
            return max(base, blend);
          }
          
          vec3 differenceBlend(vec3 base, vec3 blend) {
            return abs(base - blend);
          }
          
          //////////////////////////////
          // Main Fragment Function   //
          //////////////////////////////
          void main() {
            // Base transition with displacement
            vec4 baseColor = baseTransition();
            // Fractal effect (driven by u_time + fractalIntensity)
            vec3 fractalEffect = newShaderEffect(gl_FragCoord.xy) * u_fractalIntensity;
            
            // Blend the fractal effect in different ways
            vec3 blendResult;
            if (u_blendMode < 0.33) {
              blendResult = colorDodgeBlend(baseColor.rgb, fractalEffect);
            } else if (u_blendMode < 0.66) {
              blendResult = lightenBlend(baseColor.rgb, fractalEffect);
            } else {
              blendResult = differenceBlend(baseColor.rgb, fractalEffect);
            }
            
            // Final color
            vec3 finalColor = mix(baseColor.rgb, blendResult, u_fractalIntensity);
            outColor = vec4(finalColor, baseColor.a);
          }
        `;

        this.program = this.createShaderProgram();
        this.setupBuffers();
        this.loadTextures();
        this.loadDispTexture();
        this.setupEventListeners();

        this.render(); // Start the loop
      }

      // A helpful utility for smoothing transitions
      smoothStep(edge0, edge1, x) {
        const t = Math.max(0, Math.min(1, (x - edge0) / (edge1 - edge0)));
        return t * t * (3.0 - 2.0 * t);
      }

      createShaderProgram() {
        const gl = this.gl;
        const vertexShader = gl.createShader(gl.VERTEX_SHADER);
        gl.shaderSource(vertexShader, this.vertexShaderSource);
        gl.compileShader(vertexShader);
        if (!gl.getShaderParameter(vertexShader, gl.COMPILE_STATUS)) {
          console.error('Vertex shader error:', gl.getShaderInfoLog(vertexShader));
        }

        const fragmentShader = gl.createShader(gl.FRAGMENT_SHADER);
        gl.shaderSource(fragmentShader, this.fragmentShaderSource);
        gl.compileShader(fragmentShader);
        if (!gl.getShaderParameter(fragmentShader, gl.COMPILE_STATUS)) {
          console.error('Fragment shader error:', gl.getShaderInfoLog(fragmentShader));
        }

        const program = gl.createProgram();
        gl.attachShader(program, vertexShader);
        gl.attachShader(program, fragmentShader);
        gl.linkProgram(program);
        if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
          console.error('Program linking error:', gl.getProgramInfoLog(program));
        }
        return program;
      }

      setupBuffers() {
        const gl = this.gl;
        // Full-screen quad
        const positionBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
        const positions = [
          -1.0, -1.0,
           1.0, -1.0,
          -1.0,  1.0,
          -1.0,  1.0,
           1.0, -1.0,
           1.0,  1.0
        ];
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(positions), gl.STATIC_DRAW);

        const texCoordBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, texCoordBuffer);
        const texCoords = [
          0.0, 0.0,
          1.0, 0.0,
          0.0, 1.0,
          0.0, 1.0,
          1.0, 0.0,
          1.0, 1.0
        ];
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(texCoords), gl.STATIC_DRAW);

        gl.useProgram(this.program);
        const posLoc = gl.getAttribLocation(this.program, 'a_position');
        const texLoc = gl.getAttribLocation(this.program, 'a_texCoord');

        gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
        gl.enableVertexAttribArray(posLoc);
        gl.vertexAttribPointer(posLoc, 2, gl.FLOAT, false, 0, 0);

        gl.bindBuffer(gl.ARRAY_BUFFER, texCoordBuffer);
        gl.enableVertexAttribArray(texLoc);
        gl.vertexAttribPointer(texLoc, 2, gl.FLOAT, false, 0, 0);
      }

      loadTextures() {
        const gl = this.gl;
        this.textures = [];
        this.images = [];
        this.imagePaths.forEach(path => {
          const img = new Image();
          img.src = path;
          this.images.push(img);
        });
        Promise.all(this.images.map(img => new Promise(resolve => {
          if (img.complete) resolve();
          else img.onload = resolve;
        })))
        .then(() => {
          this.images.forEach(image => {
            const texture = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, texture);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image);
            this.textures.push(texture);
          });
          this.resizeCanvas();
        })
        .catch(err => console.error('Error loading base images:', err));
      }

      loadDispTexture() {
        const gl = this.gl;
        this.dispVideoTexture = gl.createTexture();
        gl.bindTexture(gl.TEXTURE_2D, this.dispVideoTexture);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
        // Initialize with empty data
        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, 480, 270, 0, gl.RGBA, gl.UNSIGNED_BYTE, null);
      }

      updateVideoTexture() {
        // Only update if the video is actively playing & has new data
        if (!this.video.paused && this.video.readyState >= this.video.HAVE_CURRENT_DATA) {
          const gl = this.gl;
          gl.bindTexture(gl.TEXTURE_2D, this.dispVideoTexture);
          gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, this.video);
        }
      }

      setupEventListeners() {
        window.addEventListener('mousemove', e => {
          // Update mouse position
          this.mouseX = e.clientX;
          this.mouseY = e.clientY;
          // Mark time for displacement-video threshold
          this.lastMouseMoveTime = performance.now() / 1000;
        });

        // Device orientation (mobile)
        if (window.DeviceOrientationEvent) {
          if (typeof DeviceOrientationEvent.requestPermission === 'function') {
            const motionBtn = document.getElementById('motionBtn');
            motionBtn.style.display = 'block';
            motionBtn.addEventListener('click', () => {
              DeviceOrientationEvent.requestPermission()
                .then(response => {
                  if (response === 'granted') {
                    window.addEventListener('deviceorientation', e => {
                      let gamma = e.gamma || 0;
                      let beta = e.beta || 0;
                      this.mouseX = ((gamma + 90) / 180) * window.innerWidth;
                      this.mouseY = ((beta + 180) / 360) * window.innerHeight;
                      this.lastMouseMoveTime = performance.now() / 1000;
                    });
                    motionBtn.style.display = 'none';
                  }
                })
                .catch(console.error);
            });
          } else {
            window.addEventListener('deviceorientation', e => {
              let gamma = e.gamma || 0;
              let beta = e.beta || 0;
              this.mouseX = ((gamma + 90) / 180) * window.innerWidth;
              this.mouseY = ((beta + 180) / 360) * window.innerHeight;
              this.lastMouseMoveTime = performance.now() / 1000;
            });
          }
        }

        window.addEventListener('resize', () => {
          this.resizeCanvas();
        });
      }

      resizeCanvas() {
        this.canvas.width = window.innerWidth;
        this.canvas.height = window.innerHeight;
        this.gl.viewport(0, 0, this.canvas.width, this.canvas.height);
      }

      render() {
        const gl = this.gl;
        const now = performance.now() / 1000;
        const dt = now - this.lastFrameTime;
        this.lastFrameTime = now;

        // 1) Displacement Video threshold
        const timeSinceMove = now - this.lastMouseMoveTime;
        if (timeSinceMove < this.moveThreshold) {
          if (this.video.paused) {
            this.video.play().catch(err => console.error("Video play error:", err));
          }
        } else {
          if (!this.video.paused) {
            this.video.pause();
          }
        }

        // 2) Advance fractal time by mouse velocity
        const dx = this.mouseX - this.lastMouseX;
        const dy = this.mouseY - this.lastMouseY;
        const distance = Math.sqrt(dx*dx + dy*dy);
        const speedFactor = 0.015; 
        this.fractalTime += distance * speedFactor;
        this.lastMouseX = this.mouseX;
        this.lastMouseY = this.mouseY;

        this.updateVideoTexture();

        gl.clearColor(0, 0, 0, 1);
        gl.clear(gl.COLOR_BUFFER_BIT);

        // Bail out until images load
        if (!this.textures || this.textures.length < 2) {
          requestAnimationFrame(() => this.render());
          return;
        }

        gl.useProgram(this.program);

        // =========================================================
        // ========== NEW: MAP (mouseX, mouseY) => (r, angle) =====
        // =========================================================
        const centerX = this.canvas.width * 0.5;
        const centerY = this.canvas.height * 0.5;
        const maxRadius = Math.sqrt(centerX*centerX + centerY*centerY); 

        // Distance from center:
        let dxC = this.mouseX - centerX;
        let dyC = this.mouseY - centerY;
        let r = Math.sqrt(dxC*dxC + dyC*dyC) / maxRadius; 
        // r in [0..1]

        // Angle in [-PI..PI]
        let angle = Math.atan2(dyC, dxC);
        // Convert angle to [0..1]
        let angleNorm = (angle + Math.PI) / (2.0 * Math.PI);

        // We'll use the "angleNorm" to pick images:
        const imageCount = this.imagePaths.length;
        const floatIndex = angleNorm * imageCount;  
        // e.g. if angleNorm = 0.5, floatIndex = 3.5 => between image 3 and image 4
        let baseIndex = Math.floor(floatIndex) % imageCount;
        let nextIndex = (baseIndex + 1) % imageCount;

        // fractional part determines the transition between these two images
        let fracPart = floatIndex - Math.floor(floatIndex);
        // We can smooth it to avoid abrupt changes:
        let easedFrac = this.smoothStep(0.05, 0.95, fracPart);

        // We'll store that into "this.currentTransition" or we can just use it directly:
        this.currentTransition += (easedFrac - this.currentTransition) * 0.1; 
        // 0.1 is a smoothing factor â€“ bigger â†’ faster match, smaller â†’ more drifting transitions

        // Meanwhile, let fractalIntensity = r
        let fractalIntensity = r;

        // We'll pick a "blendMode" from angleNorm as well, for fun:
        // (If you prefer a random or noise-based approach, thatâ€™s possible too.)
        let blendMode = angleNorm;  // 0..1

        // Now we have our three main parameters:
        //   imageIndex, nextIndex, this.currentTransition
        //   fractalIntensity
        //   blendMode
        // =========================================================

        // Uniforms
        const resLoc              = gl.getUniformLocation(this.program, 'u_resolution');
        const timeLoc             = gl.getUniformLocation(this.program, 'u_time');
        const transLoc            = gl.getUniformLocation(this.program, 'u_transitionProgress');
        const fractalIntensityLoc = gl.getUniformLocation(this.program, 'u_fractalIntensity');
        const blendModeLoc        = gl.getUniformLocation(this.program, 'u_blendMode');
        
        const img0Loc            = gl.getUniformLocation(this.program, 'u_image0');
        const img1Loc            = gl.getUniformLocation(this.program, 'u_image1');
        const dispVideoLoc       = gl.getUniformLocation(this.program, 'u_dispVideo');
        const dispAmountLoc      = gl.getUniformLocation(this.program, 'u_dispAmount');
        const dispScaleLoc       = gl.getUniformLocation(this.program, 'u_dispScale');

        // Pass uniform values
        gl.uniform2f(resLoc, this.canvas.width, this.canvas.height);
        gl.uniform1f(timeLoc, this.fractalTime);
        gl.uniform1f(transLoc, this.currentTransition);
        gl.uniform1f(fractalIntensityLoc, fractalIntensity);
        gl.uniform1f(blendModeLoc, blendMode);

        // Bind base images
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, this.textures[baseIndex]);
        gl.uniform1i(img0Loc, 0);

        gl.activeTexture(gl.TEXTURE1);
        gl.bindTexture(gl.TEXTURE_2D, this.textures[nextIndex]);
        gl.uniform1i(img1Loc, 1);

        // Displacement video
        gl.activeTexture(gl.TEXTURE2);
        gl.bindTexture(gl.TEXTURE_2D, this.dispVideoTexture);
        gl.uniform1i(dispVideoLoc, 2);

        // Displacement settings
        gl.uniform1f(dispAmountLoc, 0.05);
        gl.uniform1f(dispScaleLoc, 1.0);

        gl.drawArrays(gl.TRIANGLES, 0, 6);
        requestAnimationFrame(() => this.render());
      }
    }

    window.addEventListener('load', () => {
      new OrganicFluidTransition();
    });
  </script>
</body>
</html>
